## ๐งช ูุซุงูโูุง ุงุฒ ุงุณุชูุงุฏู ุชุงุจุน `cleanize_text`

ุชุงุจุน `cleanize_text` ุจุฑุง ุชูุฒุณุงุฒ ูุชูู ูุงุฑุณ (ุดุนุฑุ ฺฏูุชุงุฑุ ุฏุงุฏูโูุง ููุฒุฏุงุฑ) ุทุฑุงุญ ุดุฏู. ุฎุฑูุฌ ุดุงูู ุชูฺฉูโูุง ุชูุฒ ู ูุชู ููุง ุงุณุช.

### ๐น ูุฑูุฏ ุจู ุตูุฑุช ุฑุดุชู

```python
from cleanize_text import cleanize_text

text = "ูููโ ุงุฒ ุขู ุฑูุฒ ฺฉู ุฏุฑ ุจูุฏู ุชูุงู ุขุฒุงุฏูุ ฑฒณดต!"
tokens, cleaned = cleanize_text(text)

print("๐งผ ุชูฺฉูโูุง:", tokens)
print("๐ ูุชู ููุง:", cleaned)
